{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nel_1\\AppData\\Local\\Temp\\ipykernel_23052\\3339299637.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    23481\n",
      "0    21417\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "true_df = pd.read_csv('./True.csv')\n",
    "fake_df = pd.read_csv('./Fake.csv')\n",
    "true_df['label'] = 0\n",
    "fake_df['label'] = 1\n",
    "true_df = true_df[['text','label']]\n",
    "fake_df = fake_df[['text','label']]\n",
    "dataset = pd.concat([true_df , fake_df])\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac = 1)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def clean_data(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub('[^a-zA-Z]' , ' ' , text)\n",
    "    token = text.split() \n",
    "    news = [lemmatizer.lemmatize(word) for word in token if not word in stopwords]  \n",
    "    clean_news = ' '.join(news) \n",
    "    \n",
    "    return clean_news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13761    ridiculous article politico pretend non biased...\n",
      "12814    kiev reuters ukrainian lawmaker thursday shelv...\n",
      "1740     pretty much america agree donald trump need sp...\n",
      "9997     washington reuters democratic front runner hil...\n",
      "15211    coincidence evidence keep magically appearing ...\n",
      "Name: text, dtype: object\n",
      "13761    1\n",
      "12814    0\n",
      "1740     1\n",
      "9997     0\n",
      "15211    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset['text'] = dataset['text'].apply(lambda x : clean_data(x))\n",
    "vectorizer = TfidfVectorizer(max_features = 50000 , lowercase=False , ngram_range=(1,2))\n",
    "X = dataset.iloc[:5000,0]\n",
    "y = dataset.iloc[:5000,1]\n",
    "print(X.head())\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93      1211\n",
      "           1       0.90      0.99      0.94      1289\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.94      0.94      0.94      2500\n",
      "weighted avg       0.94      0.94      0.94      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X , test_X , train_y , test_y = train_test_split(X , y , test_size = 0.5 ,random_state = 0)\n",
    "vec_train = vectorizer.fit_transform(train_X)\n",
    "vec_train = vec_train.toarray()\n",
    "vec_test = vectorizer.transform(test_X).toarray()\n",
    "train_data = pd.DataFrame(vec_train , columns=vectorizer.get_feature_names_out())\n",
    "test_data = pd.DataFrame(vec_test , columns= vectorizer.get_feature_names_out())\n",
    "clf = RandomForestClassifier( max_depth = 5, n_estimators = 30, min_samples_split=3, max_leaf_nodes=5)\n",
    "clf.fit(train_data, train_y)\n",
    "predictions = clf.predict(test_data)\n",
    "print(classification_report(test_y , predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb617c5004eb51001b1261fe8fb1e311bfd962946fd4f9d54afee99a9ffc8a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
