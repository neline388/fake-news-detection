{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nel_1\\AppData\\Local\\Temp\\ipykernel_15396\\1314585710.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    23481\n",
      "0    21417\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "true_df = pd.read_csv('./True.csv')\n",
    "fake_df = pd.read_csv('./Fake.csv')\n",
    "true_df['label'] = 0\n",
    "fake_df['label'] = 1\n",
    "true_df = true_df[['text','label']]\n",
    "fake_df = fake_df[['text','label']]\n",
    "dataset = pd.concat([true_df , fake_df])\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac = 1)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def clean_data(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub('[^a-zA-Z]' , ' ' , text)\n",
    "    token = text.split() \n",
    "    news = [lemmatizer.lemmatize(word) for word in token if not word in stopwords]  \n",
    "    clean_news = ' '.join(news) \n",
    "    \n",
    "    return clean_news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15518    american need put american citizen first dump ...\n",
      "6330     washington reuters president elect donald trum...\n",
      "18845    refugee ghana arrested dragging young woman te...\n",
      "11156    border patrol council president brandon judd v...\n",
      "8644     ted nugent woke wrong side bed wednesday morni...\n",
      "Name: text, dtype: object\n",
      "15518    1\n",
      "6330     0\n",
      "18845    1\n",
      "11156    1\n",
      "8644     1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset['text'] = dataset['text'].apply(lambda x : clean_data(x))\n",
    "vectorizer = TfidfVectorizer(max_features = 50000 , lowercase=False , ngram_range=(1,2))\n",
    "X = dataset.iloc[:2000,0]\n",
    "y = dataset.iloc[:2000,1]\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       864\n",
      "           1       0.92      0.95      0.94       936\n",
      "\n",
      "    accuracy                           0.93      1800\n",
      "   macro avg       0.93      0.93      0.93      1800\n",
      "weighted avg       0.93      0.93      0.93      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X , test_X , train_y , test_y = train_test_split(X , y , test_size = 0.9 ,random_state = 0)\n",
    "vec_train = vectorizer.fit_transform(train_X)\n",
    "vec_train = vec_train.toarray()\n",
    "vec_test = vectorizer.transform(test_X).toarray()\n",
    "train_data = pd.DataFrame(vec_train , columns=vectorizer.get_feature_names_out())\n",
    "test_data = pd.DataFrame(vec_test , columns= vectorizer.get_feature_names_out())\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_y)\n",
    "predictions = clf.predict(test_data)\n",
    "print(classification_report(test_y , predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb617c5004eb51001b1261fe8fb1e311bfd962946fd4f9d54afee99a9ffc8a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
